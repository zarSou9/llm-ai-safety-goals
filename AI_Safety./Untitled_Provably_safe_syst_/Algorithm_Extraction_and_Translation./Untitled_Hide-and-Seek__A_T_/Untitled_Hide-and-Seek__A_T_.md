### Paper

```json
{
	"id": "https://arxiv.org/abs/2005.00130",
	"arxiv_id": "2005.00130",
	"url": "https://arxiv.org/abs/2005.00130",
	"title": "Hide-and-Seek: A Template for Explainable AI",
	"published_date": "2020-04-30T00:00:00.000Z",
	"abstract": "Lack of transparency has been the Achilles heal of Neural Networks and their wider adoption in industry. Despite significant interest this shortcoming has not been adequately addressed. This study proposes a novel framework called Hide-and-Seek (HnS) for training Interpretable Neural Networks and establishes a theoretical foundation for exploring and comparing similar ideas. Extensive experimentation indicates that a high degree of interpretability can be imputed into Neural Networks, without sacrificing their predictive power.",
	"citation_count": 5,
	"influential_citation_count": 0,
	"ref": "45760"
}
```

### Explanation

This paper proposes a framework called Hide-and-Seek for making neural networks more interpretable during training, which relates to the sub-goal of algorithm extraction by potentially making it easier to understand and translate the learned algorithms within neural networks into verifiable code, though it focuses more on interpretability during training rather than post-hoc extraction.
