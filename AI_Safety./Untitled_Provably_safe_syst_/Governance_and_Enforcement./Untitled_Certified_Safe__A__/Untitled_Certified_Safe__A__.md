### Paper

```json
{
	"id": "https://arxiv.org/abs/2408.06210",
	"arxiv_id": "2408.06210",
	"url": "https://arxiv.org/abs/2408.06210",
	"title": "Certified Safe: A Schematic for Approval Regulation of Frontier AI",
	"published_date": "2024-08-12T00:00:00.000Z",
	"abstract": "Recent and unremitting capability advances have been accompanied by calls for comprehensive, rather than patchwork, regulation of frontier artificial intelligence (AI). Approval regulation is emerging as a promising candidate. An approval regulation scheme is one in which a firm cannot legally market, or in some cases develop, a product without explicit approval from a regulator on the basis of experiments performed upon the product that demonstrate its safety. This approach is used successfully by the FDA and FAA. Further, its application to frontier AI has been publicly supported by many prominent stakeholders. This report proposes an approval regulation schematic for only the largest AI projects in which scrutiny begins before training and continues through to post-deployment monitoring. The centerpieces of the schematic are two major approval gates, the first requiring approval for large-scale training and the second for deployment. Five main challenges make implementation difficult: noncompliance through unsanctioned deployment, specification of deployment readiness requirements, reliable model experimentation, filtering out safe models before the process, and minimizing regulatory overhead. This report makes a number of crucial recommendations to increase the feasibility of approval regulation, some of which must be followed urgently if such a regime is to succeed in the near future. Further recommendations, produced by this report's analysis, may improve the effectiveness of any regulatory regime for frontier AI.",
	"citation_count": 0,
	"influential_citation_count": 0,
	"ref": "61606"
}
```

### Explanation

This paper proposes a two-stage approval regulation framework for large AI systems, similar to FDA/FAA models, where companies must obtain regulatory approval both before training and deployment of frontier AI systems - directly addressing how to implement practical governance mechanisms for ensuring AI safety. The proposal aligns closely with the governance sub-goal by outlining specific regulatory structures and approval processes that could help ensure only demonstrably safe AI systems are developed and deployed.
