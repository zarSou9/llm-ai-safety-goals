### Paper

```json
{
	"id": "https://arxiv.org/abs/2409.02779",
	"arxiv_id": "2409.02779",
	"url": "https://arxiv.org/abs/2409.02779",
	"title": "Governing dual-use technologies: Case studies of international security agreements and lessons for AI governance",
	"published_date": "2024-09-04T00:00:00.000Z",
	"abstract": "International AI governance agreements and institutions may play an important role in reducing global security risks from advanced AI. To inform the design of such agreements and institutions, we conducted case studies of historical and contemporary international security agreements. We focused specifically on those arrangements around dual-use technologies, examining agreements in nuclear security, chemical weapons, biosecurity, and export controls. For each agreement, we examined four key areas: (a) purpose, (b) core powers, (c) governance structure, and (d) instances of non-compliance. From these case studies, we extracted lessons for the design of international AI agreements and governance institutions. We discuss the importance of robust verification methods, strategies for balancing power between nations, mechanisms for adapting to rapid technological change, approaches to managing trade-offs between transparency and security, incentives for participation, and effective enforcement mechanisms.",
	"citation_count": 0,
	"influential_citation_count": 0,
	"ref": "33505"
}
```

### Explanation

This paper analyzes historical international agreements governing dual-use technologies (like nuclear and chemical weapons) to extract lessons for designing effective AI governance frameworks, with particular focus on verification, enforcement, and incentive structures - making it directly relevant to developing global policies and standards for ensuring AI safety compliance. The case studies examine how different governance approaches have succeeded or failed in practice, providing concrete insights for implementing international AI safety standards and enforcement mechanisms.
