### Description

Define the fundamental safety properties that must be guaranteed to prevent catastrophic outcomes. This includes identifying and formalizing both universal safety constraints (like preventing deception or power-seeking) and domain-specific requirements based on the system's capabilities and context of use.

### Questions

- How can we formally define and detect emergent capabilities in AI systems before they manifest, to ensure safety properties remain valid as systems develop new competencies?

- What mathematical frameworks could allow us to prove that a set of safety properties remains complete and consistent even when composed with arbitrary learned behaviors or when the system is placed in novel environments?

- How can we develop rigorous methods to identify and formalize implicit safety properties that humans rely on but rarely explicitly state, such as common sense constraints or basic ethical principles?

- What formal approaches could allow us to define safety properties that are robust to potential ontological shifts in an AI system's world model while still remaining mathematically precise and verifiable?

- How can we create formal safety properties that prevent deceptive behavior while accounting for the possibility that deception itself might emerge from seemingly benign optimization processes?

- What mathematical frameworks would allow us to define safety properties that remain meaningful and enforceable across different levels of system abstraction, from low-level computation to high-level reasoning?

- How can we develop methods to formally verify that a set of safety properties is sufficient to prevent catastrophic outcomes without requiring explicit enumeration of all possible failure modes?
