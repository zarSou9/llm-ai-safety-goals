### Paper

```json
{
	"id": "https://arxiv.org/abs/2411.08981",
	"arxiv_id": "2411.08981",
	"url": "https://arxiv.org/abs/2411.08981",
	"title": "Reliability, Resilience and Human Factors Engineering for Trustworthy AI Systems",
	"published_date": "2024-11-13T00:00:00.000Z",
	"abstract": "As AI systems become integral to critical operations across industries and services, ensuring their reliability and safety is essential. We offer a framework that integrates established reliability and resilience engineering principles into AI systems. By applying traditional metrics such as failure rate and Mean Time Between Failures (MTBF) along with resilience engineering and human reliability analysis, we propose an integrate framework to manage AI system performance, and prevent or efficiently recover from failures. Our work adapts classical engineering methods to AI systems and outlines a research agenda for future technical studies. We apply our framework to a real-world AI system, using system status data from platforms such as openAI, to demonstrate its practical applicability. This framework aligns with emerging global standards and regulatory frameworks, providing a methodology to enhance the trustworthiness of AI systems. Our aim is to guide policy, regulation, and the development of reliable, safe, and adaptable AI technologies capable of consistent performance in real-world environments.",
	"citation_count": 1,
	"influential_citation_count": 0,
	"ref": "19163"
}
```

### Explanation

This paper proposes a framework that applies traditional reliability engineering principles and metrics to AI systems, aiming to prevent failures and ensure consistent safe performance. While this work contributes to general AI safety, it primarily focuses on near-term system reliability rather than directly addressing existential risks from advanced agentic AI systems.
