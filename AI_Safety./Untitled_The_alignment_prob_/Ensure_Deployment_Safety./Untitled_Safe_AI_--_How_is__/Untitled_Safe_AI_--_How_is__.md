### Paper

```json
{
	"id": "https://arxiv.org/abs/2201.10436",
	"arxiv_id": "2201.10436",
	"url": "https://arxiv.org/abs/2201.10436",
	"title": "Safe AI -- How is this Possible?",
	"published_date": "2023-02-06T00:00:00.000Z",
	"abstract": "Ttraditional safety engineering is coming to a turning point moving from deterministic, non-evolving systems operating in well-defined contexts to increasingly autonomous and learning-enabled AI systems which are acting in largely unpredictable operating contexts. We outline some of underlying challenges of safe AI and suggest a rigorous engineering framework for minimizing uncertainty, thereby increasing confidence, up to tolerable levels, in the safe behavior of AI systems.",
	"citation_count": 0,
	"influential_citation_count": 0,
	"ref": "24267"
}
```

### Explanation

This paper examines the shift from traditional safety engineering approaches to new frameworks needed for AI systems that can learn and operate autonomously in unpredictable environments, proposing methods to increase confidence in AI safety through uncertainty reduction. The paper's focus on developing rigorous engineering frameworks for ensuring AI safety directly relates to mitigating risks from agentic AI systems, though it appears to take a more general safety engineering perspective rather than specifically addressing existential risks.
