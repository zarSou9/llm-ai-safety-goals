### Paper

```json
{
	"id": "https://arxiv.org/pdf/2302.00813.pdf",
	"arxiv_id": "2302.00813",
	"url": "https://arxiv.org/pdf/2302.00813.pdf",
	"title": "Goal Alignment: A Human-Aware Account of Value Alignment Problem",
	"published_date": "2023-10-26T00:00:00.000Z",
	"abstract": "Value alignment problems arise in scenarios where the specified objectives of an AI agent don't match the true underlying objective of its users. The problem has been widely argued to be one of the central safety problems in AI. Unfortunately, most existing works in value alignment tend to focus on issues that are primarily related to the fact that reward functions are an unintuitive mechanism to specify objectives. However, the complexity of the objective specification mechanism is just one of many reasons why the user may have misspecified their objective. A foundational cause for misalignment that is being overlooked by these works is the inherent asymmetry in human expectations about the agent's behavior and the behavior generated by the agent for the specified objective. To address this lacuna, we propose a novel formulation for the value alignment problem, named goal alignment that focuses on a few central challenges related to value alignment. In doing so, we bridge the currently disparate research areas of value alignment and human-aware planning. Additionally, we propose a first-of-its-kind interactive algorithm that is capable of using information generated under incorrect beliefs about the agent, to determine the true underlying goal of the user.",
	"citation_count": 2,
	"influential_citation_count": 0,
	"ref": "98303"
}
```

### Explanation

This paper proposes a new way to frame the value alignment problem by focusing on the mismatch between how humans expect AI systems to behave and how they actually behave based on specified objectives, introducing an interactive algorithm to help determine users' true goals. This directly addresses AI safety by helping ensure AI systems better understand and align with human intentions, reducing risks of misaligned behavior that could lead to loss of control.
