### Paper

```json
{
	"id": "https://arxiv.org/abs/2406.04231",
	"arxiv_id": "2406.04231",
	"url": "https://arxiv.org/abs/2406.04231",
	"title": "Quantifying Misalignment Between Agents: Towards a Sociotechnical Understanding of Alignment",
	"published_date": "2024-06-06T00:00:00.000Z",
	"abstract": "Existing work on the alignment problem has focused mainly on (1) qualitative descriptions of the alignment problem; (2) attempting to align AI actions with human interests by focusing on value specification and learning; and/or (3) focusing on a single agent or on humanity as a monolith. Recent sociotechnical approaches highlight the need to understand complex misalignment among multiple human and AI agents. We address this gap by adapting a computational social science model of human contention to the alignment problem. Our model quantifies misalignment in large, diverse agent groups with potentially conflicting goals across various problem areas. Misalignment scores in our framework depend on the observed agent population, the domain in question, and conflict between agents' weighted preferences. Through simulations, we demonstrate how our model captures intuitive aspects of misalignment across different scenarios. We then apply our model to two case studies, including an autonomous vehicle setting, showcasing its practical utility. Our approach offers enhanced explanatory power for complex sociotechnical environments and could inform the design of more aligned AI systems in real-world applications.",
	"citation_count": 0,
	"influential_citation_count": 0,
	"ref": "95191"
}
```

### Explanation

This paper proposes a quantitative framework for measuring misalignment between multiple AI and human agents with different goals, moving beyond simplified single-agent alignment scenarios to better understand complex real-world situations where multiple stakeholders may have conflicting interests. This work is relevant to AI safety as it helps identify and measure potential misalignment risks in multi-agent systems before they lead to loss of control or other catastrophic outcomes.
