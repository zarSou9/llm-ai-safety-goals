### Paper

```json
{
	"id": "https://arxiv.org/abs/2412.14186",
	"arxiv_id": "2412.14186",
	"url": "https://arxiv.org/abs/2412.14186",
	"title": "Towards AI-$45^{\\circ}$ Law: A Roadmap to Trustworthy AGI",
	"published_date": "2024-12-08T00:00:00.000Z",
	"abstract": "Ensuring Artificial General Intelligence (AGI) reliably avoids harmful behaviors is a critical challenge, especially for systems with high autonomy or in safety-critical domains. Despite various safety assurance proposals and extreme risk warnings, comprehensive guidelines balancing AI safety and capability remain lacking. In this position paper, we propose the \\textit{AI-\\textbf{$45^{\\circ}$} Law} as a guiding principle for a balanced roadmap toward trustworthy AGI, and introduce the \\textit{Causal Ladder of Trustworthy AGI} as a practical framework. This framework provides a systematic taxonomy and hierarchical structure for current AI capability and safety research, inspired by Judea Pearl's ``Ladder of Causation''. The Causal Ladder comprises three core layers: the Approximate Alignment Layer, the Intervenable Layer, and the Reflectable Layer. These layers address the key challenges of safety and trustworthiness in AGI and contemporary AI systems. Building upon this framework, we define five levels of trustworthy AGI: perception, reasoning, decision-making, autonomy, and collaboration trustworthiness. These levels represent distinct yet progressive aspects of trustworthy AGI. Finally, we present a series of potential governance measures to support the development of trustworthy AGI.",
	"citation_count": 0,
	"influential_citation_count": 0,
	"ref": "08323"
}
```

### Explanation

This paper proposes a framework called the "AI-45Â° Law" and "Causal Ladder of Trustworthy AGI" that aims to balance AI safety with capability development through a hierarchical structure addressing alignment, intervention, and reflection. The framework is directly relevant to AI safety as it provides a systematic approach to building trustworthy AGI systems that maintain human control while mitigating catastrophic risks.
