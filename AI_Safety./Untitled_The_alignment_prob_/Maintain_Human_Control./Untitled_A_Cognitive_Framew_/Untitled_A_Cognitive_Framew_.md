### Paper

```json
{
	"id": "https://arxiv.org/abs/2204.02889",
	"arxiv_id": "2204.02889",
	"url": "https://arxiv.org/abs/2204.02889",
	"title": "A Cognitive Framework for Delegation Between Error-Prone AI and Human Agents",
	"published_date": "2023-02-07T00:00:00.000Z",
	"abstract": "With humans interacting with AI-based systems at an increasing rate, it is necessary to ensure the artificial systems are acting in a manner which reflects understanding of the human. In the case of humans and artificial AI agents operating in the same environment, we note the significance of comprehension and response to the actions or capabilities of a human from an agent's perspective, as well as the possibility to delegate decisions either to humans or to agents, depending on who is deemed more suitable at a certain point in time. Such capabilities will ensure an improved responsiveness and utility of the entire human-AI system. To that end, we investigate the use of cognitively inspired models of behavior to predict the behavior of both human and AI agents. The predicted behavior, and associated performance with respect to a certain goal, is used to delegate control between humans and AI agents through the use of an intermediary entity. As we demonstrate, this allows overcoming potential shortcomings of either humans or agents in the pursuit of a goal.",
	"citation_count": 6,
	"influential_citation_count": 0,
	"ref": "20840"
}
```

### Explanation

This paper explores using cognitive models to predict both human and AI behavior in order to optimally delegate control between them, which directly relates to maintaining human control by enabling dynamic switching of authority based on predicted performance. The approach aims to improve overall system safety by having an intermediary system that can determine when humans versus AI agents are better suited to handle different situations.
