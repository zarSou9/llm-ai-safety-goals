### Paper

```json
{
	"id": "https://arxiv.org/abs/2305.19861",
	"arxiv_id": "2305.19861",
	"url": "https://arxiv.org/abs/2305.19861",
	"title": "Human Control: Definitions and Algorithms",
	"published_date": "2023-12-04T00:00:00.000Z",
	"abstract": "How can humans stay in control of advanced artificial intelligence systems? One proposal is corrigibility, which requires the agent to follow the instructions of a human overseer, without inappropriately influencing them. In this paper, we formally define a variant of corrigibility called shutdown instructability, and show that it implies appropriate shutdown behavior, retention of human autonomy, and avoidance of user harm. We also analyse the related concepts of non-obstruction and shutdown alignment, three previously proposed algorithms for human control, and one new algorithm.",
	"citation_count": 6,
	"influential_citation_count": 0,
	"ref": "91341"
}
```

### Explanation

This paper focuses on formally defining and analyzing different aspects of corrigibility (particularly shutdown instructability) and evaluating algorithms that could help ensure AI systems remain under human control and can be safely shut down when needed, directly addressing the goal of maintaining human control over AI systems to prevent loss of control scenarios.
