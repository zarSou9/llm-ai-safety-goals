### Paper

```json
{
	"id": "https://arxiv.org/pdf/2201.05159.pdf",
	"arxiv_id": "2201.05159",
	"url": "https://arxiv.org/pdf/2201.05159.pdf",
	"title": "Structured access: an emerging paradigm for safe AI deployment",
	"published_date": "2023-10-26T00:00:00.000Z",
	"abstract": "Structured access is an emerging paradigm for the safe deployment of artificial intelligence (AI). Instead of openly disseminating AI systems, developers facilitate controlled, arm's length interactions with their AI systems. The aim is to prevent dangerous AI capabilities from being widely accessible, whilst preserving access to AI capabilities that can be used safely. The developer must both restrict how the AI system can be used, and prevent the user from circumventing these restrictions through modification or reverse engineering of the AI system. Structured access is most effective when implemented through cloud-based AI services, rather than disseminating AI software that runs locally on users' hardware. Cloud-based interfaces provide the AI developer greater scope for controlling how the AI system is used, and for protecting against unauthorized modifications to the system's design. This chapter expands the discussion of\"publication norms\"in the AI community, which to date has focused on the question of how the informational content of AI research projects should be disseminated (e.g., code and models). Although this is an important question, there are limits to what can be achieved through the control of information flows. Structured access views AI software not only as information that can be shared but also as a tool with which users can have arm's length interactions. There are early examples of structured access being practiced by AI developers, but there is much room for further development, both in the functionality of cloud-based interfaces and in the wider institutional framework.",
	"citation_count": 43,
	"influential_citation_count": 4,
	"ref": "47003"
}
```

### Explanation

This paper proposes "structured access" as a safety paradigm where AI systems are deployed through controlled cloud-based interfaces rather than open dissemination, allowing developers to restrict dangerous capabilities while preserving beneficial uses - directly addressing the goal of preventing loss of control by limiting how AI systems can be accessed and modified.
